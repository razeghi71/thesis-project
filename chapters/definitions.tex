
\فصل{مفاهیم اولیه}

در این بخش مفاهیم و تعاریفی را که در خلال پایان‌نامه از آن‌ها استفاده کرده‌ایم، تبیین می‌کنیم.

\قسمت{پیچیدگی محاسباتی}

\شروع{تعریف}
به مسائلی که در زمان چندجمله‌ای\پانویس{polynomial time} بر حسب اندازه‌ی ورودی توسط یک ماشین تورینگ\پانویس{Turing machine} قطعی\پانویس{deterministic} قابل حل باشند، مسائل دسته‌ی $\mathrm{\mathop{P}}$ و به مسائلی که در زمان چندجمله‌ای توسط یک ماشین تورینگ غیرقطعی\پانویس{nondeterministic} قابل حل باشند مسائل دسته‌ی $\mathrm{\mathop{NP}}$ می‌گوییم.
\پایان{تعریف}

اهمیت دسته‌ی مسائل $\mathrm{\mathop{P}}$ از این جهت است که در طراحی الگوریتم‌ها، همواره علاقه‌مند هستیم که الگوریتم مورد نظر در زمان قابل قبولی اجرا شود. برای مشخص و قابل تعریف بودن مفهوم «زمان قابل قبول»، زمان چندجمله‌ای برحسب اندازه‌ی ورودی را، زمان قابل قبول برای اجرای الگوریتم تعریف می‌کنیم. به این ترتیب در طراحی الگوریتم‌ها مطلوب است که الگوریتم مورد نظر در دسته‌ی $\mathrm{\mathop{P}}$ قرار بگیرد.

\شروع{قضیه}
یک مسئله در دسته‌ی $\mathrm{\mathop{NP}}$ قرار دارد، اگر یک ماشین تورینگ قطعی بتواند در زمان چند‌جمله‌ای بر حسب اندازه‌ی ورودی، با گرفتن ورودی مسئله و یک اثبات برای بله بودن جواب مسئله، این اثبات را وارسی کند.
\پایان{قضیه}

معمولاً طراحی یک الگوریتم وارسی‌کننده\پانویس{verifier} برای یک مسئله، بسیار آسان‌تر از طراحی یک الگوریتم برای حل آن است. در نتیجه انتظار می‌رود که مسائل دسته‌ی $\mathrm{\mathop{NP}}$ مسائل سخت‌تری نسبت به مسائل دسته‌ی $\mathrm{\mathop{P}}$ باشند. یکی از سوالات کلیدی شاخه‌ی علوم کامپیوتر در عصر حاضر این است که آیا این دو دسته برابر هستند یا خیر. باور عمومی بر این است که $\mathrm{\mathop{P}} \neq \mathrm{\mathop{NP}}$، ولی تاکنون کسی موفق به اثبات این مطلب نشده است.

\شروع{تعریف}
به دسته‌ای از مسائل که هر مسئله‌ای از دسته‌ی $\mathrm{\mathop{NP}}$ در زمان چندجمله‌ای به آن کاهش‌پذیر\پانویس{reducible} باشد، مسائل ان‌پی-سخت می‌گویند.
\پایان{تعریف}

این تعریف به این معنی است که این دسته از مسائل حداقل به سختی هر مسئله‌ی $\mathrm{\mathop{NP}}$ دیگری هستند. در نتیجه با فرض این که
$\mathrm{\mathop{P}} \neq \mathrm{\mathop{NP}}$،
این مسائل در زمان چندجمله‌ای غیرقابل حل هستند. شکل \رجوع{fig:problem classes} نمودار ون\پانویس{Venn diagram} این دسته‌بندی از مسائل بر حسب پیچیدگی\پانویس{complexity} را نمایش می‌دهد.

\شروع{شکل}[h]
\تنظیم‌ازوسط
\درج‌تصویر[width=12cm]{problem_classes_inclusion.png}
\برچسب{fig:problem classes}
\شرح{نمودار ون دسته‌های پیچیدگی مسائل}
\پایان{شکل}

بسیاری از مسائل بهینه‌سازی مهم و پایه‌ای
ان‌پی-سخت هستند. بنابراین، با فرض
$\mathrm{\mathop{P}} \neq \mathrm{\mathop{NP}}$
نمی‌توان الگوریتم‌هایی با زمان چندجمله‌ای برای این مسائل ارائه کرد.
روش‌های متداول برای برخورد با این مسائل عبارت‌اند از:

\شروع{فقرات}
\فقره با استفاده از روش‌های جست‌وجوی تمام حالات، 
مسئله را در زمان غیرچندجمله‌ای حل نمود.
\فقره در زمان چندجمله‌ای، تقریبی از جواب بهینه را به دست آورد.
\فقره مسئله را فقط برای حالات خاص حل نمود.
\پایان{فقرات}

به الگوریتم‌های مبتنی بر روش اول، الگوریتم‌های جُستاری\پانویس{heuristic} می‌گوییم و الگوریتم‌های مبتنی بر روش دوم را، الگورتیم‌های تقریبی می‌نامیم.

مسائل مورد بررسی در این پایان‌نامه نیز در حالت کلی ان‌پی-سخت هستند. روی‌کرد این پایان‌نامه برای حل این مسائل، استفاده از روش سوم، یعنی حل مسئله در حالت‌های خاص است.


\قسمت{مدل‌های محاسباتی}

در این رساله گاهی می‌خواهیم نشان دهیم هیچ الگوریتمی نمی‌تواند در کم‌تر از تعداد مشخصی گام مسئله‌ی مورد نظرمان را حل کنیم و به این ترتیب نشان دهیم الگوریتم‌مان بهینه است. برای این کار باید تعریف مشخصی از مدل محاسباتی و اعمال اولیه‌ی آن داشته باشیم. در این نوشتار از مدل درخت محاسباتی جبری\پانویس{algebraic computation tree} استفاده می‌کنیم.
\شروع{تعریف}
یک درخت محاسباتی جبری روی $\IR$ یک درخت\پانویس{tree} ریشه‌دار\پانویس{rooted} دودویی\پانویس{binary}
$T$
است که در آن هر گره\پانویس{node}
$v$
یکی از سه نقش زیر را دارد:
\شروع{فقرات}
\فقره \متن‌سیاه{گره محاسبه:} این گره دقیقاً یک فرزند\پانویس{child} دارد. این گره تابع $f_v$ را محاسبه می‌کند که تابع $f_v$ یکی از سه حالت زیر را دارد:
\[
f_v = f_1 \circ f_2 \text{\; یا \;} f_v = c \circ f_1 \text{\; یا \;} f_v = \sqrt{f_1}
\]
که $f_1$ و $f_2$ برابر تابع یکی از اجداد $v$ در $T$ یا برابر یکی $x_1, \ldots, x_n$~ها است.
\فقره \متن‌سیاه{گره مقایسه:} این گره دقیقاً دو فرزند دارد و یکی از سه عمل زیر را انجام می‌دهد:
\[
f_{v_1} > 0 \text{\; یا \;} f_{v_1} \geq 0 \text{\; یا \;} f_{v_1} = 0
\]
بسته به درستی گزاره‌ی این گره، پردازش ورودی به یکی از دو فرزند این گره منتقل می‌شود.
\فقره \متن‌سیاه{گره خروجی:} این گره برگ\پانویس{leaf} است و یکی از دو برچسب «بله» یا «خیر» را دارد.
\پایان{فقرات}
\پایان{تعریف}

یک درخت محاسباتی جبری یک تابع بولی
$\IR^n \rightarrow \set{\text{ بله }, \text{ خیر }}$
را محاسبه می‌کند. به این ترتیب که پردازش یک ورودی در ریشه‌ی درخت آغاز می‌شود و محاسبات لازم در گره‌های محاسبه انجام می‌شود و بسته به درستی گزاره‌ی گره‌های مقایسه، پردازش ورودی به طبقات پایین‌تر درخت می‌رسد تا بالاخره مسیر پردازش در یک برگ متوقف شود. برچسب آن گره مقدار تابع بولی را به ازای آن ورودی مشخص می‌کند. در واقع هر درخت محاسبه‌ی جبری مسئله‌ی عضویت یک نقطه از $\IR^n$ را در مجموعه‌ی $W$ حل می‌کند.

به طول مسیر پردازش ورودی $x$ در درخت $T$ هزینه‌ی این پردازش می‌گوییم و آن را با
$\mathrm{\mathrm{cost}}(x,T)$
نمایش می‌دهیم. به بیش‌ترین مقدار
$\mathrm{\mathrm{cost}}(x,T)$
به ازای ورودی‌های مختلف $x$ هزینه‌ی درخت $T$ می‌گوییم و آن را با
$\mathrm{\mathrm{cost}}(T)$
نمایش می‌دهیم.

بن‌اور \مرجع{ben1983lower} کران پایینی برای حل مسئله‌ی عضویت در مجموعه‌ی $W$ بر مبنای مدل درخت محاسبه‌ی جبری اثبات می‌کند:
\شروع{قضیه}
\برچسب{قضیه:بن‌اور}
فرض کنید مجموعه‌ی $W$ در فضای $\IR^n$ دارای $m$ مولفه‌ی هم‌بندی\پانویس{connected component} باشد. در این صورت هر درخت محاسبه‌ی $T$ برای مسئله‌ی $W$ حداقل هزینه‌ی
$\Omega(\log m - n)$
دارد.
\پایان{قضیه}

\شروع{نتیجه}
\برچسب{نتیجه:کران پایین برای تمایز عناصر}
\مرجع{ben1983lower}
با داشتن $n$ عدد حقیقی $x_1, \ldots, x_n$ تصمیم‌گیری این که آیا این $n$ نقطه دوبه‌دو متمایز هستند تحت مدل درخت محاسبه‌ی جبری در زمان کم‌تر از $O(n \log n)$ ممکن نیست.
\پایان{نتیجه}

\قسمت{مفاهیم هندسی}
پیش از پرداختن به مسئله‌ی $k$-مرکز، لازم است که برخی مفاهیم هندسی را بیان کنیم.
ابتدایی‌ترین مفهوم هندسی مورد استفاده در این رساله، مفهوم نقطه است.

\شروع{تعریف}[نقطه]
به هر عضو از فضای $\IR^n$ یک نقطه می‌گوییم.
\پایان{تعریف}

یکی از مفاهیمی که تعریف مسئله‌ی $k$-مرکز بر آن مبتنی است، مفهوم فاصله و فضای متریک است.

\شروع{تعریف}[فاصله]
به تابع
$d : X \times X \rightarrow \IR$
یک تابع فاصله روی فضای $X$ می‌گوییم، هرگاه به ازای هر $x,y,z \in X$ دارای خواص زیر باشد:
\شروع{فقرات}
\فقره اصل تفکیک\پانویس{separation axiom}:
$d(x,y) \geq 0$
\فقره اصل انطباق\پانویس{coincidence axiom}:
$d(x,y) = 0 \Leftrightarrow x=y$
\فقره تقارن\پانویس{symmetry}:
$d(x,y) = d(y,x)$
\فقره نابرابری مثلثی\پانویس{triangle inequality}:
$d(x,y) \leq d(x,z) + d(z,y)$
\پایان{فقرات}
\پایان{تعریف}

\شروع{تعریف}[فضای متریک]
به یک فضای مجهز به تابع فاصله یک فضای متریک می‌گوییم.
\پایان{تعریف}

یک روش طبیعی برای تعریف تابع فاصله در فضاهای برداری، استفاده از مقیاس بردارها است. در ادامه این مفهوم را تبیین می‌کنیم.

%فضای برداری رو هم تعریف کنیم؟
\شروع{تعریف}[فضای برداری مقیاس‌پذیر]
فضای برداری $V$ را روی زیرمیدانی از اعداد مختلط در نظر بگیرید. تابع
$p : V \rightarrow \IR$
را یک مقیاس روی فضای $V$ می‌گوییم هرگاه به ازای هر بردار $\mathbf{u}$ و $\mathbf{v}$ و هر اسکالر\پانویس{scalar} ویژگی‌های زیر را داشته باشد:
\شروع{فقرات}
\فقره همگنی مطلق\پانویس{absolute homogeneity}:
$p(a\mathbf{v}) = \card{a} p(\mathbf{v})$
\فقره نابرابری مثلثی:
$p(\mathbf{v} + \mathbf{u}) \leq p(\mathbf{v}) + p(\mathbf{u})$
\فقره
$p(\mathbf{v}) = 0 \Rightarrow \mathbf{v} = \mathbf{0}$
\پایان{فقرات}
\پایان{تعریف}

روشن است که به ازای تابع مقیاس $p$ روی فضای برداری $V$، تابع $d(x,y) = p(x-y)$ یک تابع فاصله است.

مقیاس اقلیدسی و منهتنی\پانویس{Manhattan} از رایج‌ترین توابع فاصله در کاربردهای روزمره هستند. در ادامه به تعریف این توابع ویژه می‌پردازیم.

\شروع{تعریف}[مقیاس $l_p$]
فضای برداری $n$~بعدی $V$ را در نظر بگیرید. به ازای عدد حقیقی $p$، مقیاس $l_p$ را روی این فضا با $\left\| \mathbf{x} \right\|_p$ نشان می‌دهیم و به این صورت تعریف می‌کنیم:
\[
\left\| \mathbf{x} \right\|_p = \left( \sum_{i=1}^n x_i^p \right)^\frac{1}{p}
\]
\پایان{تعریف}

\شروع{تعریف}[فضای منهتنی]
فضای برداری $V$ را به همراه تابع فاصله‌ی $l_1$ یک فضای اقلیدسی می‌گوییم.
\پایان{تعریف}

\شروع{تعریف}[فضای اقلیدسی]
فضای برداری $V$ را به همراه تابع فاصله‌ی $l_2$ یک فضای اقلیدسی می‌گوییم.
\پایان{تعریف}

\شروع{تعریف}[فضای بیشین\پانویس{maximum space}]
فضای برداری $V$ را به همراه تابع فاصله‌ی $l_\infty$ یک فضای بیشین می‌گوییم. مقیاس $l_\infty$ به این صورت تعریف می‌شود:
\[
\left\| \mathbf{x} \right\|_\infty = \lim_{p \rightarrow \infty} \left\| \mathbf{x} \right\|_p = \max_{1 \leq i \leq n}\set{x_i}
\]
\پایان{تعریف}

مفهوم بنیادی دیگری که در تعریف مسئله‌ی $k$-مرکز به آن احتیاج داریم، مفهوم گوی است. این مفهوم در ادامه تشریح گشته است.

\شروع{تعریف}[گوی]
به مجموعه‌ای از نقاط فضای متریک $\IR^n$ که فاصله‌ی آن‌ها از نقطه‌ی $c$ حداکثر $r$ باشد، که $c$ نقطه‌ای از فضا و $r$ عددی حقیقی و مثبت است، گوی به مرکز $c$ و به شعاع $r$ می‌گوییم.
\پایان{تعریف}

یک گوی واحد با توجه به تابع فاصله، اشکال مختلفی می‌تواند داشته باشد. اگر توابع $l_1$، $l_2$ و $l_\infty$ به عنوان تابع فاصله مورد استقاده قرار گیرند، گوی واحد به ترتیب به شکل مربع مورب، دایره و مربع موازی محورهای مختصات خواهد بود. شکل \رجوع{fig:ball_shapes} این اشکال را نمایش می‌دهد.

\شروع{شکل}[h]
\تنظیم‌ازوسط
\subfigure[فضای منهتنی]{
\درج‌تصویر{l1_ball}

}
\subfigure[فضای اقلیدسی]{
\درج‌تصویر{l2_ball}

}
\subfigure[فضای بیشین]{
\درج‌تصویر{linf_ball}
}
\برچسب{fig:ball_shapes}
\شرح{شکل یک گوی}
\پایان{شکل}

همان‌طور که مشاهده می‌شود، گوی‌های فضای منهتنی با یک دوران $45^\circ$ بر گوی‌های فضای بیشین منطبق می‌شوند. به این ترتیب بررسی مسئله در این دو فضا معادل است. برای سادگی از این پس قضایای مرتبط را فقط برای فضای بیشین بیان می‌کنیم، ولی خواننده باید مطلع باشد که این قضایا با اندکی تغییر در مورد فضای منهتنی نیز برقرار هستند.

مجموعه‌ی نقاط داخل یک گوی را نقاط پوشش داده شده توسط آن گوی می‌گوییم. با داشتن این تعاریف، می‌توانیم به تعریف مسئله‌ی $k$-مرکز بپردازیم.


\قسمت{داده‌ساختار درخت جست‌وجوی محدوده‌ای}

در بخشی از این رساله از داده‌ساختار درخت جست‌وجوی محدوده‌ای\پانویس{range search tree} \مرجع{bentley1979decomposable} برای حل مسائل مورد بررسی این نوشتار استفاده شده است. درخت جست‌وجوی محدوده‌ای یک درخت مرتب\پانویس{ordered} است که برای نگه‌داری نقاط یک فضای $d$~بعدی استفاده می‌شود. با استفاده از این داده‌ساختار می‌توانیم مجموعه‌ی نقاط داخل یک محدوده‌ی مستطیلی با اضلاع موازی محورهای مختصات را در زمان مناسبی محاسبه کرد. همچنین می‌توان اطلاعاتی تجمعی در مورد این نقاط را در همان زمان بازیابی کرد. در این قسمت به معرفی این داده‌ساختار می‌پردازیم.

\زیرقسمت{ساختار}

درخت جست‌وجوی محدوده‌ای به صورت بازگشتی تعریف می‌شود. درخت جست‌وجوی محدوده‌ای یک‌بعدی یک درخت دودویی متوازن\پانویس{balanced} مرتب است که نقاط در برگ‌های آن ذخیره می‌شوند و هر گره داخلی آن بیش‌ترین مقدار داده‌های موجود در برگ‌های زیردرخت مربوط به خود را ذخیره می‌کند. علاوه بر آن هر گره داخلی می‌تواند اطلاعاتی تجمعی، مانند تعداد نقاط یا مجموع وزن نقاط زیردرخت مربوط به خود را نیز ذخیره کند. برای ابعاد بالاتر، درخت جست‌وجوی محدوده‌ای به صورت درخت دودویی متوازن مرتب چندطبقه تعریف می‌شود. طبقه‌‌ی اول آن یک درخت جست‌وجوی محدوده‌ای یک‌بعدی برای تصویر نقاط روی بعد اول است. در هر گره داخلی این درخت، یک درخت جست‌وجوی محدوده‌ای برای نقاط موجود در زیردرخت به آن گره روی $d-1$ بعد دیگر است. به این ترتیب هر طبقه‌ی این داده‌ساختار بر حسب یکی از ابعاد فضا مرتب شده است. شکل~\رجوع{شکل:درخت جست‌وجوی محدوده‌ای} شمایی از ساختار این درخت را در حالت دوبعدی نشان می‌دهد.

\شروع{شکل}[th]
\تنظیم‌ازوسط
\درج‌تصویر
[width=9cm]{rangetree2d}
\شرح{ساختار درخت جست‌وجوی محدوده‌ای دوبعدی}
\برچسب{شکل:درخت جست‌وجوی محدوده‌ای}
\پایان{شکل}

\زیرقسمت{ایجاد داده‌ساختار}

برای ایجاد این داده‌ساختار برای نقاط یک‌بعدی می‌توانیم آن‌ها را مرتب کنیم و در برگ‌ها قرار دهیم. سپس گره‌های داخلی را از پایین به بالا ساخته و اطلاعات لازم را برای هر گره محاسبه کنیم. به این ترتیب داده‌ساختار در زمان $O(n \log n)$ ایجاد می‌شود. برای داده‌های با ابعاد بالاتر، می‌توانیم داده‌ها را بر حسب بعد اول در یک درخت جست‌وجوی محدوده‌ای یک‌بعدی قرار دهیم و در هر گره داخلی آن داده‌ساختار را به صورت بازگشتی روی $d-1$ بعد دیگر ایجاد کنیم. با توجه به ابرخطی\پانویس{superlinear} بودن تابع $n \log^{d-1} n$ و این که هر نقطه در هر عمق از درخت جست‌وجوی محدوده‌ای یک‌بعدی دقیقاً یک بار ظاهر می‌شود، پس هزینه‌ی ساخت درخت به ازای هر عمق از درخت طبقه‌ی اول، حداکثر $O(n \log n)$ است. با توجه به این که عمق طبقه‌ی اول داده‌ساختار برابر $\log n$ است، پس هزینه‌ی کل ساخت درخت جست‌وجوی محدوده‌ای $d$~بعدی برای $n$ نقطه حداکثر برابر $O(n \log^d n)$ است.

این روش ساخت قابل به‌بود است. نشان می‌دهیم درخت جست‌وجوی محدوده‌ای دو‌بعدی برای $n$ در زمان $O(n \log n)$ قابل ساخت است. برای این کار نقاط را نسبت به هر دو مولفه مرتب می‌کنیم. سپس درخت جست‌وجوی بازه‌ای یک‌بعدی را نسبت به مولفه‌ی اول می‌سازیم. با توجه به این که نقاط از پیش نسبت به مولفه‌ی دوم مرتب شده‌اند، درخت جست‌وجوی محدوده‌ای طبقه‌ی دوم در هر گره داخلی طبقه‌ی اول در زمان خطی نسبت به تعداد نقاط آن گره قابل ساخت است. با توجه به این که در هر عمق از درخت طبقه‌ی اول، هر نقطه دقیقاً یک بار ظاهر شده است، هزینه‌ی ایجاد داده‌ساختار به ازای هر عمق از درخت طبقه‌ی اول حداکثر $O(n)$ است. ارتفاع این درخت $\log n$ است. پس هزینه‌ی کل ایجاد این داده‌ساختار حداکثر $O(n \log n)$ است. با استفاده از این روش، درخت جست‌وجوی محدوده‌ای برای ابعاد بالاتر در زمان $O(n \log^{d-1} n)$ قابل ایجاد است.

به جز طبقه‌ی آخر این داده‌ساختار که هر نقطه فقط در یک برگ آن ذخیره می‌شود، در سایر طبقات هر نقطه دقیقاً یک بار در هر طبقه و در کل طبقه $\log n$ بار ذخیره می‌شود. پس هر نقطه $\log^{d-1} n$ بار ذخیره می‌شود. پس فضای مصرفی این داده‌ساختار $O(n \log^{d-1} n)$ است.


\زیرقسمت{پاسخ به پرسش‌ها}

این داده‌ساختار می‌تواند به پرسش‌هایی راجع به اطلاعات تجمعی نقاط داخل یک جعبه\پانویس{box} با وجوه موازی محورهای مختصات پاسخ دهد. ابتدا نحوه‌ی پاسخ به این پرسش را در درخت جست‌وجوی محدوده‌ای یک‌بعدی بررسی می‌کنیم. برای این کار دو سر بازه‌ی مورد نظر را در درخت دودویی مرتب جست‌وجو می‌کنیم. مسیر جست‌وجوی این دو مقدار در درخت، حداکثر $2 \log n$ گره را مشخص می‌کند که اجتماع مجزای آن‌ها مجموعه‌ی نقاط داخل محدوده‌ی مورد پرسش است. پس با ترکیب اطلاعات تجمعی این گره‌ها می‌توان پاسخ این پرسش را محاسبه نمود. هزینه‌ی این کار برابر هزینه‌ی جست‌وجوی دو سر بازه در درخت دودویی مرتب، برابر $O(n \log n)$ است.

در درخت جست‌وجوی محدوده‌ای $d$~بعدی برای پاسخ به چنین پرسشی، ابتدا در طبقه‌ی اول، مشابه حالت یک‌بعدی، گره‌هایی را که اجتماع مجزای آن‌ها در بعد اول نقاط داخل محدوده‌ی مورد نظر را مشخص می‌کنند پیدا می‌کنیم. سپس در هر یک از این گره‌ها پرسشی برای درخت جست‌وجوی محدوده‌ای $(d-1)$~بعدی روی سایر ابعاد ایجاد می‌کنیم. این پرسش به طور بازگشتی پاسخ داده می‌شود. سپس از ترکیب پاسخ این پرسش‌ها، پاسخ پرسش اصلی را محاسبه می‌کنیم. زمان مورد نیاز برای شناسایی گره‌های طبقه‌ی اول حداکثر $\log n$ است و زمان پاسخ به هر یک از $O(\log n)$ پرسش جدید، طبق فرض استقرا برابر $O(\log^{d-1} n)$ است. به این ترتیب زمان کل هزینه شده در این روش برابر $O(\log^d n)$ است. گیباس \مرجع{chazelle1986fractional1}\مرجع{chazelle1986fractional2} نشان داده است که این زمان به $O(\log^{d-1} n)$ قابل کاهش است.


\قسمت{مسئله‌ی $k$-مرکز}

ورودی مسئله‌ی $k$-مرکز تعدادی نقطه در فضای $\IR^n$ و عدد صحیح $k$ است. هدف یافتن $k$ گوی هم‌شعاع است، طوری که همه‌ی نقاط ورودی پوشش داده شوند و شعاع گوی‌ها کمینه باشد. مقدار بهینه‌ی این شعاع را با $r^*$ نمایش می‌دهیم. در این‌جا تعریف گوی با توجه به تابع فاصله‌ی فضا مشخص می‌شود. در این رساله به‌طور خاص بر مطالعه‌ی توابع $l_2$ و $l_\infty$ تاکید داریم. در تعمیمی از این مسئله، تعدادی از نقاط می‌توانند خارج از محدوده‌ی پوشش قرار بگیرند. به این نقاط، نقاط پرت می‌گوییم. در مسئله‌ی $k$-مرکز با نقاط پرت، حداکثر تعداد نقاط پرت مجاز را با $z$ نمایش می‌دهیم و در مسئله‌ی $k$-مرکز با نقاط پرت وزن‌دار، حداکثر مجموع وزن مجاز نقاط پرت را با $w_z$ نمایش می‌دهیم. بسته به تعریف مسئله، تعداد یا مجموع وزن نقاط پرت کران بالایی دارد که هر جواب ممکنی، باید حداکثر این مقدار از نقاط را به عنوان نقاط پرت قرار دهد.
% این‌جا دقیقاً چی می‌خوایم بگیم؟ تعریف مسئله رو که توی مقدمه گفتیم. چه حرفی برای گفتن باقی مونده؟

%سهند محض رضای خدا دست به این نزن. برگشتم خودم کاملش میکنم. واقعا کاری نداره. تو فقط همون بخش خودت رو بنویسی کافیه. خواهش میکنم.
%سلام کیانا. ببخشید که روت رو زمین می‌زنم، ولی شرایط بحرانی بود. مطمئن هستم وقتی بزرگ‌تر بشی دلیل کارم رو می‌فهمی.
